{"data":{"markdownRemark":{"html":"<h2>Joint Random variables</h2>\n<p>More often, in real life, we see two or more random variables related to each other. For example, height of a person is related to weight of a person. Amount of investment is related to amount of return. Or maybe two variables are not related at all, but can occur jointly - flipping a coin and rolling a die.</p>\n<p>For simplicity, let's take two random variables A and B.</p>\n<p>A = flipping a coin, B = rolling a die</p>\n<p>$$P(A \\cap B) = {1 \\over 12} \\rightarrow Joint,random,variable$$</p>\n<p>In statistics, we measure how strongly two random variables are related by two metrics - <strong>Covariance</strong> and <strong>Correlation</strong>.</p>\n<h2>Correlation</h2>\n<h4>Positive correlation</h4>\n<p>A positive correlation exists between two variables A and B when A increases, B also increases and B decreases when A decreases. Graph between A and B would look like the following.</p>\n<p><img src=\"images/positive-correlation.svg\" alt=\"Positive correlation\"></p>\n<p><strong><em>Examples</em></strong></p>\n<ul>\n<li>Height v/s Weight of a person</li>\n<li>Walking distance v/s calories burnt</li>\n<li>Product quality v/s sales</li>\n</ul>\n<h4>Perfect Positive correlation</h4>\n<p>A perfect positive correlation exists if there is a positive linear association between two variables. Which means, given variable A, we can exactly predict the value of B by multiplying with a positive number.</p>\n<p><img src=\"images/perfect-positive-correlation.svg\" alt=\"Perfect positive correlation\"></p>\n<p><strong><em>Examples</em></strong></p>\n<ul>\n<li>Length of a square v/s it's circumference</li>\n<li>Weight in kilos v/s weight in pounds</li>\n</ul>\n<h4>Negative correlation</h4>\n<p>A negative correlation exists between two variables A and B, if A decreases when B increases and A increases when B decreases.</p>\n<p><img src=\"images/negative-correlation.svg\" alt=\"Negative correlation\"></p>\n<p><strong><em>Examples</em></strong></p>\n<ul>\n<li>Mobile screen time v/s remaining battery percentage</li>\n<li>Current run rate v/s Required run rate (in Cricket)</li>\n</ul>\n<h4>Perfect Negative correlation</h4>\n<p>A perfect negative correlation exists if there is a negative linear association between two variables.</p>\n<p><img src=\"images/perfect-negative-correlation.svg\" alt=\"Perfect negative correlation\"></p>\n<p><strong><em>Examples</em></strong></p>\n<ul>\n<li>Power v/s focal length of a lens</li>\n<li>Frequency v/s wavelength of light</li>\n</ul>\n<h4>Zero correlation</h4>\n<p>If two variables are independent of each other, then there is no correlation or zero correlation.</p>\n<p><img src=\"images/zero-correlation.svg\" alt=\"Zero correlation\"></p>\n<p><strong><em>Examples</em></strong></p>\n<ul>\n<li>Bitcoin price v/s speed of light</li>\n<li>Your mobile usage per day v/s neighbor's electricity bill</li>\n</ul>\n<h3>Calculating covariance and correlation</h3>\n<p>$$Covariance(x, y) = { {\\sum<em>{i=1}^n (x</em>i - \\bar{x}) \\cdot (y<em>i - \\bar{y})} \\over n-1} = E[XY] - \\mu</em>x\\mu_y$$ </p>\n<p>$$Correlation(x, y) = {Covariance(x, y) \\over \\sigma<em>x \\cdot \\sigma</em>y}$$</p>\n<pre><code class=\"language-python\">import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.array([50, 30, 67, 103, 49, 156, 33, 78])\ny = np.array([601, 304, 801, 905, 359, 1100, 205, 801])\n\nplt.scatter(x, y)\n</code></pre>\n<p><img src=\"images/correlation-scatter.png\" alt=\"Correlation scatter\"></p>\n<pre><code class=\"language-python\">def covariance(x, y):\n    if len(x) != len(y) or len(x) &#x3C; 1: return None\n    mean_x, mean_y = np.mean(x), np.mean(y)\n    numerator = np.sum([(a - mean_x) * (b - mean_y) for (a, b) in zip(x, y)])\n    return numerator / (len(x) - 1)\n\ndef correlation(x, y):\n    cov = covariance(x, y)\n    if cov: return cov / (np.std(x, ddof=1) * np.std(y, ddof=1))\n\nprint(f'Covariance = {covariance(x, y)}')\nprint(f'Correlation = {correlation(x, y)}')\n</code></pre>\n<pre><code>Covariance = 12194.142857142857\nCorrelation = 0.9072220542468226\n</code></pre>\n<h3>Variance of sum and difference</h3>\n<p>If we have two random variables X and Y,</p>\n<p>Variance of X + Y is given by,</p>\n<p>$$Var(X + Y) = \\sigma<em>x + \\sigma</em>y = \\sigma<em>x^2 + \\sigma</em>y^2 + 2 \\cdot Cov(X, Y)$$</p>\n<p>Variance of X - Y is given by,</p>\n<p>$$Var(X - Y) = \\sigma<em>x - \\sigma</em>y = \\sigma<em>x^2 + \\sigma</em>y^2 - 2 \\cdot Cov(X, Y)$$</p>","frontmatter":{"title":"Covariance and Correlation"}}},"pageContext":{"slug":"/stats/covariance-correlation/"}}